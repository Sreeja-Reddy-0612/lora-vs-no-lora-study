"""
Inference-only entry point (NO TRAINING)
"""

from utils.tokenizer import load_tokenizer
from inference.qlora_inference import load_qlora_model
from eval.generation_eval import generate_response


def main():
    model_name = "gpt2-medium"
    adapter_path = "../artifacts/adapters/qlora"

    print("ðŸ”¹ Loading tokenizer...")
    tokenizer = load_tokenizer(model_name)

    print("ðŸ”¹ Loading QLoRA adapter...")
    model = load_qlora_model(model_name, adapter_path)

    print("ðŸ”¹ Running inference...")
    response = generate_response(
        model,
        tokenizer,
        "Capital of France?"
    )

    print("\nâœ… Model response:")
    print(response)


if __name__ == "__main__":
    main()
